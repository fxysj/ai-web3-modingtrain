数据预处理工具特点
这个数据预处理工具专为 Web3.0 领域设计，具有以下特点：
领域特定处理：内置 Web3.0 领域术语表，能够识别和标准化区块链、加密货币相关术语
全面的文本清洗：能够处理 URL、HTML 标签、电子邮件、以太坊地址等特殊内容
表情符号处理：将表情符号转换为文本描述，保留情感信息
数值特征提取：专门处理价格、百分比等 Web3.0 领域常见的数值数据
特征工程：提取 Web3.0 特定特征，如协议名称、术语频率等
灵活的输出格式：支持多种输出格式，包括字典列表、DataFrame 和 PyTorch 数据集


使用示例
1. 单文本预处理
from utils.data_preprocessing import Web3DataPreprocessor
from transformers import AutoTokenizer

# 加载分词器
tokenizer = AutoTokenizer.from_pretrained("bert-base-chinese")

# 创建预处理器
preprocessor = Web3DataPreprocessor(
    tokenizer=tokenizer,
    language='chinese',
    lower_case=True,
    remove_stopwords=True,
    normalize_web3_terms=True
)

# 示例文本
text = "📢【重要通知】以太坊Layer 2解决方案将降低Gas费并提高交易速度！" + \
       "当前ETH价格为$1,800，较昨日上涨2.5%。0x1234...abcd是一个测试地址。"

# 处理文本
processed = preprocessor.process_text(text)

print("原始文本:", text)
print("\n清洗后的文本:", processed["cleaned_text"])
print("\n标准化后的文本:", processed["normalized_text"])
print("\n分词结果:", processed["tokens"])
print("\n数值特征:", {k: v for k, v in processed.items() if k.startswith("numeric_")})
print("\nWeb3特征:", {k: v for k, v in processed.items() if k.startswith("web3_")})

2. 处理数据集
from utils.data_preprocessing import Web3DataPreprocessor, Web3DatasetProcessor
from transformers import AutoTokenizer

# 加载分词器
tokenizer = AutoTokenizer.from_pretrained("bert-base-chinese")

# 创建预处理器
preprocessor = Web3DataPreprocessor(tokenizer=tokenizer)

# 创建数据集处理器
dataset_processor = Web3DatasetProcessor(preprocessor)

# 示例数据集
dataset = [
    {
        "id": 1,
        "text": "如何在以太坊上部署智能合约？",
        "label": 0
    },
    {
        "id": 2,
        "text": "比特币价格预测：未来一周BTC会继续上涨吗？",
        "label": 1
    }
]

# 处理数据集
processed_dataset = dataset_processor.process_dataset(dataset)

print("处理后的数据集:")
for item in processed_dataset[:2]:
    print(f"ID: {item['id']}, 标签: {item.get('label')}")
    print(f"清洗后的文本: {item['cleaned_text']}")
    print(f"Web3术语: {item['web3_term_counts']}")
    print("-" * 40)

3. 转换为 PyTorch 数据集
from utils.data_preprocessing import Web3DataPreprocessor, Web3DatasetProcessor
from transformers import AutoTokenizer
from torch.utils.data import DataLoader

# 加载分词器
tokenizer = AutoTokenizer.from_pretrained("bert-base-chinese")

# 创建预处理器
preprocessor = Web3DataPreprocessor(tokenizer=tokenizer)

# 创建数据集处理器
dataset_processor = Web3DatasetProcessor(preprocessor)

# 示例数据集
dataset = [
    {"text": "以太坊是一个开源的区块链平台", "label": 0},
    {"text": "比特币是第一种去中心化数字货币", "label": 1}
]

# 处理数据集
processed_dataset = dataset_processor.process_dataset(dataset)

# 创建PyTorch数据集
torch_dataset = dataset_processor.create_torch_dataset(processed_dataset)

# 创建数据加载器
dataloader = DataLoader(torch_dataset, batch_size=2)

# 测试数据加载器
batch = next(iter(dataloader))
print("批次数据:")
for key, value in batch.items():
    print(f"{key}: {value.shape}")

这个数据预处理工具可以帮助你在训练 Web3.0 相关模型时准备高质量的训练数据，提高模型的性能和对领域术语的理解能力。