脚本功能说明
这个训练脚本提供了完整的基础模型训练能力，特别针对 Web3.0 领域的特点进行了优化：
多 GPU 训练支持：使用 Accelerate 库实现分布式训练，支持数据并行和模型并行
混合精度训练：支持 FP16、BF16 和 TF32 等混合精度训练，大幅降低显存需求
梯度累积：通过梯度累积支持更大的有效批次大小，适合在有限显存下训练大模型
灵活的学习率调度：支持多种学习率调度策略，包括余弦退火、线性衰减等
模型保存策略：支持按步数或轮次保存模型，并自动保存最佳模型
LoRA 支持：可选使用 LoRA 技术进行参数高效微调，减少训练资源需求
监控和日志：集成 TensorBoard 和 WandB 等监控工具，实时跟踪训练进度
数据处理：自动加载和预处理 Web3.0 领域数据集，支持本地和远程数据加载

使用示例
以下是几种常见的使用场景：
1. 标准训练配置
python scripts/train_base_model.py \
  --model_name_or_path Qwen/Qwen2.5-14B \
  --dataset_name 0xscope/web3-trading-analysis \
  --output_dir ./web3_base_model \
  --per_device_train_batch_size 4 \
  --gradient_accumulation_steps 4 \
  --learning_rate 5e-5 \
  --num_train_epochs 3 \
  --bf16 \
  --report_to tensorboard

2. 使用 LoRA 进行参数高效微调
python scripts/train_base_model.py \
  --model_name_or_path Qwen/Qwen2.5-14B \
  --dataset_name 0xscope/web3-trading-analysis \
  --output_dir ./web3_lora_model \
  --use_lora \
  --lora_r 8 \
  --lora_alpha 32 \
  --per_device_train_batch_size 8 \
  --learning_rate 1e-4 \
  --num_train_epochs 5 \
  --bf16
3. 使用本地数据集训练
python scripts/train_base_model.py \
  --model_name_or_path Qwen/Qwen2.5-14B \
  --data_dir ./path/to/your/dataset \
  --output_dir ./web3_base_model \
  --per_device_train_batch_size 2 \
  --gradient_accumulation_steps 8 \
  --learning_rate 3e-5 \
  --num_train_epochs 4 \
  --fp16

注意事项
训练大模型需要充足的 GPU 资源，建议使用至少 80GB 显存的 A100 或 H100 GPU
如果显存不足，可以尝试减小批次大小、使用更高的梯度累积步数或启用更激进的量化
训练过程中会自动保存模型检查点，建议定期备份以防止意外中断
对于 Web3.0 领域的特定任务，可能需要调整模型架构或训练目标函数
这个脚本提供了一个强大而灵活的基础模型训练框架，你可以根据具体需求进行调整和扩展
